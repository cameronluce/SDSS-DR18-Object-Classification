{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dd2b574",
   "metadata": {},
   "source": [
    "## Neural Network Notebook for Object Classification with SDSS DR18\n",
    "\n",
    "Within this notebook, we classify objects within SDSS DR18 using a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508f388b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'skl_tts' from 'sklearn.model_selection' (/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptim\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader, TensorDataset\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m skl_tts\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder, StandardScaler\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report \u001b[38;5;28;01mas\u001b[39;00m skl_cr\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'skl_tts' from 'sklearn.model_selection' (/home/codespace/.local/lib/python3.12/site-packages/sklearn/model_selection/__init__.py)"
     ]
    }
   ],
   "source": [
    "import kagglehub #used to get the data from kaggle.com\n",
    "from kagglehub import KaggleDatasetAdapter #used to fetch the specific dataset from kaggle\n",
    "import pandas as pd #used for viewing and manipulating the data\n",
    "import matplotlib.pyplot as plt #used for data visulisation\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split as skl_tts\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report as skl_cr\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import sys, os #imports sys and os, allows for modifying the path to get functions\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\"))) #changes the path to include the py folder and its contents (parent folder)\n",
    "\n",
    "from functions import * #calls all functions from functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0714e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataGrabber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c7fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbc98a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class'].value_counts().plot(kind='bar', color = ['forestgreen', 'goldenrod', 'darkcyan'])\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439bca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['u', 'g', 'r', 'i', 'z']\n",
    "\n",
    "x = data[features]\n",
    "y = data['class']\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "yEncoded = labelEncoder.fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "xScaled = scaler.fit_transform(x)\n",
    "\n",
    "test_size = 0.2\n",
    "random_state = 12\n",
    "xTrain, xTest, yTrain, yTest = dataSplitting(xScaled, yEncoded, test_size, random_state)\n",
    "\n",
    "xTrainTensor = torch.tensor(xTrain, dtype = torch.float32) \n",
    "yTrainTensor = torch.tensor(yTrain, dtype = torch.long) \n",
    "xTestTensor = torch.tensor(xTest, dtype = torch.float32) \n",
    "yTestTensor = torch.tensor(yTest, dtype = torch.long)\n",
    "\n",
    "trainData = TensorDataset(xTrainTensor, yTrainTensor)\n",
    "testData = TensorDataset(xTestTensor, yTestTensor)\n",
    "trainLoader = DataLoader(trainData, batch_size = 64, shuffle = True)\n",
    "testLoader =  DataLoader(testData, batch_size = 64, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585506c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetworkClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c938b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = nn.CrossEntropyLoss()\n",
    "optimiser = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "epochs = 25\n",
    "lossHistory = modelTraining(model, trainLoader, criteria, optimiser, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe52cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, len(lossHistory) + 1), lossHistory, marker = 'o', color = 'g')\n",
    "plt.title(\"Training Loss over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.axhline(y = 0.170, xmin = 0, xmax = epochs, linestyle= '-', color = 'r', label = \"Loss ~ 0.170\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136fc43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEvaluationNN(model, testLoader, labelEncoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
